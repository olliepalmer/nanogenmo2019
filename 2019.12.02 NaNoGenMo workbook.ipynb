{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaNoGenMo workbook\n",
    "\n",
    "2019.12.02 (yes, later than the deadline...)\n",
    "\n",
    "This is a tidier version of my earlier code, without all the unnecessary mistakes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tracery in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (0.1.1)\n",
      "Requirement already satisfied: numpy in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (1.17.4)\n",
      "Requirement already satisfied: nltk in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (3.4.5)\n",
      "Requirement already satisfied: six in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (from nltk) (1.13.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/o/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/o/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/o/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/o/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/o/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package names to /Users/o/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# installing things\n",
    "\n",
    "\n",
    "# tracery! \n",
    "!pip3 install tracery\n",
    "\n",
    "# natural language toolkit (nltk)\n",
    "!pip3 install numpy # install numpy to start\n",
    "!pip3 install nltk # then nltk\n",
    "\n",
    "# nltk downloads\n",
    "import nltk\n",
    "nltk.download('punkt') # this needs to happen at some point\n",
    "nltk.download('averaged_perceptron_tagger') # and this\n",
    "nltk.download('maxent_ne_chunker') # and this\n",
    "nltk.download('words') # and this\n",
    "nltk.download('wordnet') # and this\n",
    "nltk.download('names')\n",
    "\n",
    "\n",
    "\n",
    "# here are some we don't need, but are fun\n",
    "# nltk.download('gutenberg')\n",
    "# nltk.download('brown')\n",
    "# nltk.download('reuters')\n",
    "# nltk.download('inaugural')\n",
    "# nltk.download('names')\n",
    "# nltk.download('state_union')\n",
    "\n",
    "\n",
    "# from nltk.corpus import gutenberg\n",
    "# from nltk.corpus import brown\n",
    "# from nltk.corpus import reuters\n",
    "# from nltk.corpus import inaugural\n",
    "# from nltk.corpus import names\n",
    "# from nltk.corpus import state_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my own data, from various sources is in the 'corpora' folder\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# define variables\n",
    "# this stuff from my own data\n",
    "townprefixes = []\n",
    "townsuffixes = []\n",
    "street = []\n",
    "stupid = []\n",
    "weputthe = []\n",
    "firstnames = []\n",
    "surnames = []\n",
    "# this stuff to come from nltk\n",
    "nouns = []\n",
    "verbs = []\n",
    "adj = []\n",
    "nn = []  # NN\tnoun, singular 'desk'\n",
    "nns = [] # NNS\tnoun plural\t'desks'\n",
    "nnp = [] # NNP\tproper noun, singular\t'Harrison'\n",
    "vbg = [] # VBG\tverb, gerund/present participle\t'taking'\n",
    "\n",
    "\n",
    "with open('corpora/townprefixes.txt','r') as f:\n",
    "    townprefixes = [line.strip() for line in f]\n",
    "with open('corpora/townsuffixes.txt','r') as f:\n",
    "    townsuffixes = [line.strip() for line in f]\n",
    "with open('corpora/monopolystreets.txt','r') as f:\n",
    "    street = [line.strip() for line in f]\n",
    "with open('corpora/words_alpha.txt','r') as f:\n",
    "    stupid = [line.strip() for line in f]\n",
    "with open('corpora/we_put_the_x_in_y.txt','r') as f:\n",
    "    weputthe = [line.strip() for line in f]\n",
    "with open('corpora/top_5494_names_us_1990.txt','r') as f:\n",
    "    firstnames = [line.strip() for line in f]\n",
    "from nltk.corpus import names\n",
    "for i in range(len(names.words())):\n",
    "    firstnames.append(names.words()[i])\n",
    "with open('corpora/top_us_surnames.txt','r') as f:\n",
    "    surnames = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "for synset in list(wordnet.all_synsets('n')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    nouns.append(word)\n",
    "for synset in list(wordnet.all_synsets('v')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    verbs.append(word)\n",
    "for synset in list(wordnet.all_synsets('a')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    adj.append(word)\n",
    "\n",
    "sentence = ''\n",
    "for synset in list(wordnet.all_synsets('n')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    sentence = sentence + word + ' '\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "length = len(tagged) - 1\n",
    "\n",
    "vbg = [item[0] for item in tagged if item[1]== 'VBG']\n",
    "nnp = [item[0] for item in tagged if item[1]== 'NNP']\n",
    "nns = [item[0] for item in tagged if item[1]== 'NNS']\n",
    "nn  = [item[0] for item in tagged if item[1]== 'NNS']\n",
    "\n",
    "# list all the fun stuff we now have\n",
    "print('loaded: \\n'\n",
    "      +'WORDNET\\n'\n",
    "      +str(len(vbg))+' VBG verbs, gerund/present\\n'\n",
    "      +str((len(nnp)+len(nnp)+len(nn)))+' nouns, of which:'\n",
    "      +str(len(nn))+' NN nouns, singular\\n'\n",
    "      +str(len(nns))+' NNS nouns, plural\\n'\n",
    "      +str(len(nnp))+' NNP nouns, proper, singular\\n'\n",
    "      +'OTHER\\n'\n",
    "      +str(len(townprefixes))+' town prefixes\\n'\n",
    "      +str(len(townsuffixes))+' town suffixes\\n'\n",
    "      +str(len(street))+' street names\\n'\n",
    "      +str(len(stupid))+' random words\\n'\n",
    "      +str(len(weputthe))+' instances of \\\"we put the...in...\\\"'\n",
    "      +str(len(firstnames))+' first names'\n",
    "      +str(len(surnames))+' surnames'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracery\n",
    "import tracery\n",
    "from tracery.modifiers import base_english\n",
    "\n",
    "# \"#something.capitalize# #category.s.capitalize#\",\n",
    "# \"#initials# #category.capitalize#\",\n",
    "# \"#initials# #superlative.capitalize# #category.capitalize.s#\",\n",
    "# \"#town# #category.capitalizeAll#\",\n",
    "# \"#firstname#\\'s #category.capitalizeAll#\",\n",
    "# \"#firstname#\\'s #superlative.capitalize# #category.capitalize#\",\n",
    "# \"#firstname#\\'s #category.capitalize.s#\",\n",
    "# \"#initials.capitalizeAll# #surname# (#category.capitalize#)\",\n",
    "# \"#initials.capitalizeAll# #surname.capitalize# #modifier.capitalize#\",\n",
    "# \"#initials.capitalizeAll# #surname.capitalize#\",\n",
    "# \"#initials.capitalizeAll# #noun.capitalize#\",\n",
    "# \"#noun.capitalize#\",\n",
    "# \"#adj.capitalize# #noun.capitalize#\",\n",
    "\n",
    "\n",
    "rules = {\n",
    "    # category\n",
    "    \"master\":\"[#setcategory#]#category##additional#\\n=================\\n\",\n",
    "    \"setcategory\":[\"[noun:#setnoun#],[adj:#setadj#],[category:#cat#],[subcat:#additional#],[additional:#setadditional#]\"],\n",
    "    \"cat\":[\"#noun.capitalize.s#\",\"#noun.capitalize.s#\",\"#adj.capitalize# #noun.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize.s#\",\"#adj.capitalize# #vbg.capitalize#\"],\n",
    "    \"vbg\":vbg,\n",
    "    \"setnoun\":[\"#nnp.capitalize#\",\"#nns.capitalize#\",\"#modifier##nns#\"],\n",
    "    \"nnp\":nnp,\n",
    "    \"nns\":nns,\n",
    "    \"setadj\":adj,\n",
    "    \"setadditional\":[\"\",\"\",\"\",\" (#noun.capitalize#)\",\" (#noun.capitalize#, #noun.capitalize#)\",\" (#noun.capitalize#, #adj.capitalize# & #adj.capitalize#)\",\" (NOT #noun.capitalize#)\"],\n",
    "    \"modifier\":[\"\",\"\",\"\",\"\",\"\",\"Paleo\",\"Crypto\",\"Pseudo\",\"Trans\",\"Neuro\",\"Arch\",\"Pre-\",\"Post-\",\"X-\",\"Anarcho\",],\n",
    "\n",
    "    # companies\n",
    "    \"listing\":[\"[#companyinfo#]\\*\\*#name.capitalize#\\*\\*\\ \\ \\n\\_#motto#\\_\\ \\ \\n#address#\\ \\ \\n☎ #phone#\\n\\n\"],\n",
    "\n",
    "    # set company info\n",
    "    \"companyinfo\":[\"[town:#settown#],[name:#setname#],[address:#setaddress#],[phone:#setphone#],[motto:#setmotto#]\"],\n",
    "\n",
    "    # town\n",
    "    \"settown\":\"#prefix.capitalize##suffix#\",\n",
    "    \"prefix\": townprefixes,\n",
    "    \"suffix\": townsuffixes,\n",
    "\n",
    "    # company name\n",
    "      \"setname\":[\n",
    "        \"#something.capitalize# #category.s.capitalize#\",\n",
    "        \"#initials# #category.capitalize#\",\n",
    "        \"#initials# #superlative.capitalize# #category.capitalize.s#\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize# #and.capitalize#\",\n",
    "        \"#noun.capitalize# #and.capitalize#\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize#\",\n",
    "        \"#initials.capitalizeAll# #surname# (#category.capitalize#)\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize# #and.capitalize#\",\n",
    "        \"#category.capitalize# (#initials.capitalizeAll# #surname.capitalize# #and#)\",\n",
    "        \"#firstname.capitalize#\\'s #category.capitalize#\",\n",
    "        \"#firstname.capitalize#\\'s #noun.capitalize#\",\n",
    "        \"#town.capitalize# #adj.capitalize#\",\n",
    "        \"#town.capitalize# #noun.capitalize#\",\n",
    "        \"#town.capitalize# #category.capitalize#\",\n",
    "        \"#town.capitalize# #adj.capitalize# #and#\",\n",
    "        \"#town.capitalize# #noun.capitalize# #and\",\n",
    "        \"#town.capitalize# #category.capitalize# #and#\",\n",
    "        \"#initials.capitalizeAll##initials.capitalizeAll##initials.capitalizeAll# #and#\",\n",
    "        \"#initials.capitalizeAll# #and# (#town.capitalize#)\",\n",
    "        \"#noun.capitalize# #and.capitalize#\",\n",
    "        \"#firstname#\\'s #superlative.capitalize# #category.capitalize#\",\n",
    "        \"#setadj.capitalize# #noun.capitalize# #initials.capitalizeAll#\"\n",
    "      ],\n",
    "    \"initials\":[\"#l.capitalize#.\",\"#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.\",\"#l.capitalize#.#l.capitalize#.\",\"#l.capitalize##l.capitalize#\",\"#firstname.capitalize# #l.capitalize#.\"],\n",
    "    \"l\":[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"],\n",
    "    \"firstname\":firstnames,\n",
    "    \"surname\":surnames,\n",
    "    \"and\":[\"& Sons\",\"& Co\",\"and Company\",\"Incorporated\",\"& #nnp.capitalize#\",\"Holdings\"],\n",
    "\n",
    "\n",
    "    # address\n",
    "    \"setaddress\": \"#streetname.capitalize#, #town.capitalize#\",\n",
    "    \"number\": [\"#d0#\",\"#d0##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\"],\n",
    "    \"streetname\":[\"#number# #street# #streettype#\",\"#number# #street# #streettype#\",\"#street# & #street#\"],\n",
    "    \"streettype\":[\"Avenue\",\"Street\",\"Road\",\"Lane\",\"Parkway\",\"St\",\"Ave\"],\n",
    "    \"street\": street,\n",
    "    \"town\": \"#prefix.capitalize##suffix#\",\n",
    "    \"zipcode\": \"#d##d##d##d##d#\",\n",
    "    \"d\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],\n",
    "    \"d0\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],\n",
    "    \"d1\":[\"0\",\"1\"],\n",
    "    \"d19\":[\"18\",\"19\",\"19\"],\n",
    "    \"d20\":[\"20\"],\n",
    "\n",
    "    # phone number\n",
    "    \"setphone\":[\"#d0##d##d#-#d##d##d##d#\"],\n",
    "\n",
    "\n",
    "    # motto\n",
    "    \"setmotto\": [\"#motto#\",\"#tellem#\",\"#weputthexiny#\",\"#weputthexiny#\",\"The #superlative# #thing# #located# #town#\",\"#owned.capitalize#\",\"#stuff#\",\"#directions#\",\"#youlike##punctuation#\",\"#youlike# \\n#directions#\",\"#localpromo#\"],\n",
    "    \"owned\":[\"#division.a# of #something.capitalize# #inc#\",\"#division.a# of #something.capitalize# #inc.capitalize#\",\"Part of the #something.capitalize# #inc#\"],\n",
    "    \"owned2\":[\"#division.a# of #acronym.capitalize# #inc#\",\"#division.a# of #acronym.capitalize# #inc.uppercase#\",\"Part of the #acronym.capitalize# #inc#\"],\n",
    "    \"acronym\": [\"#letter.uppercase#.#letter.uppercase#.\",\"#letter.uppercase#.#letter.uppercase#.#letter.uppercase#.\",\"#letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase#-#letter.uppercase#-#letter.uppercase#-#letter.uppercase#\"],\n",
    "    \"inc\": [\"Family\",\"Network\",\"Network of Companies\",\"LLC\",\"PLC\",\"L.L.C.\"],\n",
    "    \"something\": [\"#nnp#\",\"#nns#\"],\n",
    "    \"division\":[\"Proud Member\",\"Founding Member\"],\n",
    "    \"superlative\": [\"biggest\",\"best\",\"oldest\",\"rarest\",\"most sought-after\",\"nicest\",\"prettiest\"],\n",
    "    \"thing\": [\"prices\",\"selection\",\"collection\",\"range\",\"budget option\",\"#size# selection\"],\n",
    "    \"size\": [\"mid-range\",\"large-scale\",\"huge\",\"budget\",\"high budget\",\"upscale\"],\n",
    "    \"located\": [\"in\",\"near\",\"#dir# of\"],\n",
    "    \"dir\": [\"north\",\"south\",\"east\",\"west\",\"just outside\"],\n",
    "    \"stuff\": [\"#something.capitalize#, #something.capitalize#, & #something.capitalize#!\",\"#something.capitalize# • #something.capitalize# • #something.capitalize#\",\"#wevegot# #something.capitalize#!\"],\n",
    "    \"wevegot\": [\"We've got\",\"You'll love our\",\"Why not try\",\"Take a look at our\",\"Relax with\",\"Prod our\"],\n",
    "    \"directions\":[\"#action# #dir# at #town#\",\"#action# #dir# at #place#, #action# for #distance# #measurement#\",\"#place.capitalize#: #action# #dir# at #town#, #action# #dir# at #town#, #action# #dir# at #town#\"],\n",
    "    \"place\":[\"#town#\",\"Junction #d0##d#\",\"Interstate #d0##d#\",\"the #something.capitalize#\"],\n",
    "    \"action\":[\"Turn\",\"Continue Straight\",\"Continue\",\"Drive\"],\n",
    "    \"distance\": [\"#d0#\",\"#d0##d#\"],\n",
    "    \"measurement\":[\"miles\",\"feet\"],\n",
    "    \"youlike\":[\n",
    "        \"#something.capitalize# #timespan#!\",\n",
    "        \"You like #stuff.capitalize#? We've got it!\",\n",
    "        \"Have you ever wanted #something.capitalize#?\",\n",
    "        \"Have you ever wanted #something.capitalize#? We have #something.capitalize#!\",\n",
    "        \"Dreaming of #something.capitalize#?!\",\n",
    "        \"Why not try #something.capitalize# #timespan#?\",\n",
    "        \"You want #category.capitalize#? We've got #category.capitalize#!\",\n",
    "        \"#category.capitalize#: Just the way you like it\",\n",
    "        \"You've never seen #category.capitalize# this #size#\",\n",
    "        \"Our secret is in our #nnp.capitalize#\",\n",
    "        \"Family owned #nns.capitalize#\",\n",
    "    ],\n",
    "    \"timespan\":[\"now\",\"tomorrow\",\"today\",\"right now\",\"immediately\",\"the next chance you get\"],\n",
    "    \"weputthe\":[\"We put the #something# in #something.s#\"],\n",
    "    \"tell\":[\"Tell them\",\"Tell 'em\",\"Just say\"],\n",
    "    \"amazingjob\":[\"#qualifier# #job#\"],\n",
    "    \"qualifier\":[\"top\",\"local celebrity\",\"well-known\",\"your favourite\",\"imaginary friend\",\"family favourite\",\"the one and only\",\"phenomenal\",\"the best\",\"excellent\",\"mediocre\",\"mid-range\",\"smooth moving\"],\n",
    "    \"job\":[\"chef\",\"TV host\",\"Psychic\",\"carpenter\",\"dentist\",\"orthodontist\",\"paleontologist\",\"captain\",\"musician\"],\n",
    "    \"tellem\":[\"#tell# #firstname# sent you!\",\"Recommended by #amazingjob# #firstname.capitalize# #surname.capitalize#\"],\n",
    "    \"tell\":[\"Tell them\",\"Tell 'em\",\"Just say\"],\n",
    "    \"est\":[\"Established #year#\",\"Since #year#\",\"Serving #town# since #year#\",\"Helping you with #category# since #year#\",\"In #town.capitalize# since #year#\"],\n",
    "    \"year\":[\"#d19##d##d#\",\"#d19##d##d#\",\"#d20##d1##d#\"],\n",
    "    \"punctuation\":[\"!\",\".\",\"!!\",\"!\",\"!!!\",\"?!\"],\n",
    "\n",
    "\n",
    "    \"weputthexiny\":[\"#weputthe#!\",\"#weputthe#!!!\",\"#weputthe#\"],\n",
    "    \"weputthe\":weputthe,\n",
    "    \"localpromo\":[\"Hear our advert on #localstation#\",\"You might have heard about us on #localstation#\",\"Proud sponsors of #localstation#\"],\n",
    "    \"localstation\":[\"#something.capitalize# #d0##d#.#d0# FM\",\"#qualifier# local station #something.capitalize# #d0##d#.#d0# FM\",\"1#d##d#.#d0# FM\",\"the Internet\",\"the radio\"],\n",
    "    \n",
    "    # markdown stuff\n",
    "    \"markdownheader\":\"\\-\\-\\-\\nlayout: page \\ntitle: #category#\\n\\n\\-\\-\\-\\n\\n\\n\\# #category#\\n\\n\\n \",\n",
    "    \"pagetitle\":\"#category#.md\",\n",
    "    \"markdownlisting\":[\"[#companyinfo#]\\#\\# #name.capitalize# \\n\\n\\#\\# #motto#\\n\\n#address#\\ \\ \\n☎ #phone#\\n\\n\"],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "grammar = tracery.Grammar(rules) # create a grammar object from the rules\n",
    "grammar.add_modifiers(base_english) # add pre-programmed modifiers\n",
    "\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to markdown\n",
    "#\n",
    "# there's probably a more elegant way to do this\n",
    "\n",
    "for i in range(2000):\n",
    "    print (grammar.flatten(\"#master#\")) # and flatten, starting with origin rule\n",
    "    with open('website/pages/'+grammar.flatten(\"#pagetitle#\"),'w') as f:\n",
    "        f.write(grammar.flatten(\"#markdownheader#\"))\n",
    "        for j in range(random.randrange(1,100)):\n",
    "            f.write(grammar.flatten(\"#listing#\"))\n",
    "\n",
    "\n",
    "# with open('demo_output.md','w') as f:\n",
    "#     f.write('# Demo output\\n\\n')\n",
    "#     for i in range(100):\n",
    "#         heading = grammar.flatten(\"\\-\\-\\-\\-\\n\\n#master#\\n\\n\")\n",
    "#         print(heading)\n",
    "#         f.write(heading)\n",
    "#         listings = []\n",
    "#         for j in range(random.randrange(1,30)):\n",
    "#             newlisting = grammar.flatten(\"#listing#\")\n",
    "#             print(newlisting)\n",
    "#             f.write(newlisting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to alphabetise this stuff\n",
    "#\n",
    "# which we can probably do with json formatting\n",
    "#\n",
    "# a json array for the categories\n",
    "\n",
    "# !pip3 install requests\n",
    "# !pip3 install pandas\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "# here's some demo data\n",
    "\n",
    "listings = {\n",
    "        \"type\":\"directory\",\n",
    "        \"businesses\":[\n",
    "            {\n",
    "            \"name\":\"Draba Incorporated\",\n",
    "            \"street_address\": \"4751 Park Lane Avenue\",\n",
    "            \"town\":\"Alfaside\",\n",
    "            \"phone\": \"915-2187\",\n",
    "            \"motto\": \"Semantics tomorrow!!!!\",\n",
    "            \"category\": \"Nonparallel Rolling\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Aaaaaa M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"Nonparallel Rolling\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Zzzz M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"Nonparallel Rolling\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Zzzz M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"aaAAA\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },        {\n",
    "            \"name\":\"Zzzz M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"bBbbb\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },        \n",
    "                    {\n",
    "            \"name\":\"Zzzz M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"CC Rolling\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },{\n",
    "            \"name\":\"Zzzz M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"Nonparallel Rolling\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },\n",
    "            {\n",
    "            \"name\":\"Dale M. & Tai (Golfston)\",\n",
    "            \"street_address\": \"The Angel Islington & Pentonville Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"409-4399\",\n",
    "            \"motto\": \"Part of the Numbers L.L.C.\",\n",
    "            \"category\": \"Aaa\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"Nonparallel Rolling (Micky C. Hansen & Laredo)\",\n",
    "            \"street_address\": \"5001 Marylebone Station Road\",\n",
    "            \"town\":\"Golfson\",\n",
    "            \"phone\": \"885-6170\",\n",
    "            \"motto\": \"We put the 'cal' in 'electrometrical'!\",\n",
    "            \"category\": \"zed zed zed\",\n",
    "            \"category_noun\":\"Rolling\",\n",
    "        }],\n",
    "    }\n",
    "json_string = json.dumps(listings)\n",
    "json_parse = json.loads(json_string)\n",
    "\n",
    "\n",
    "\n",
    "# functions to sort data\n",
    "\n",
    "def alphabetical_businesses(d):\n",
    "    '''helper function for sorting list of dictionaries'''\n",
    "    return d.get('name',None).lower()\n",
    "\n",
    "def alphabetical_categories(d):\n",
    "    '''helper function for sorting list of dictionaries'''\n",
    "    return d.get('category',None).lower()\n",
    "\n",
    "# i = sorted(json_parse['businesses'], key=alphabetical_categories)\n",
    "\n",
    "lastcategory = 'a'\n",
    "thiscategory = 'b'\n",
    "for i in sorted(json_parse['businesses'], key=alphabetical_categories):\n",
    "    # first time, just the category - store as variable\n",
    "    # if the category is same as above, don't print it\n",
    "    thiscategory = i['category']\n",
    "    if (thiscategory != lastcategory):\n",
    "        print(thiscategory,('\\n====\\n'))\n",
    "    print(i['name'],i['phone'])\n",
    "    lastcategory = thiscategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
