{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaNoGenMo workbook\n",
    "\n",
    "2019.12.02 (yes, later than the deadline...)\n",
    "\n",
    "This is a tidier version of my earlier code, without all the unnecessary mistakes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tracery in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (0.1.1)\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/9a/a6b3168f2194fb468dcc4cf54c8344d1f514935006c3347ede198e968cb0/numpy-1.17.4-cp37-cp37m-macosx_10_9_x86_64.whl (15.1MB)\n",
      "\u001b[K     |████████████████████████████████| 15.1MB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.17.4\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 532kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/o/.local/share/virtualenvs/nanogenmo2019-i67VHn6Q/lib/python3.7/site-packages (from nltk) (1.13.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449908 sha256=d2bee998f70ef33230201558b368fe58ae3a369da292598dd54fab84e5ade2ee\n",
      "  Stored in directory: /Users/o/Library/Caches/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/o/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/o/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/o/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/o/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/o/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package names to /Users/o/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# installing things\n",
    "\n",
    "\n",
    "# tracery! \n",
    "!pip3 install tracery\n",
    "\n",
    "# natural language toolkit (nltk)\n",
    "!pip3 install numpy # install numpy to start\n",
    "!pip3 install nltk # then nltk\n",
    "\n",
    "# nltk downloads\n",
    "import nltk\n",
    "nltk.download('punkt') # this needs to happen at some point\n",
    "nltk.download('averaged_perceptron_tagger') # and this\n",
    "nltk.download('maxent_ne_chunker') # and this\n",
    "nltk.download('words') # and this\n",
    "nltk.download('wordnet') # and this\n",
    "nltk.download('names')\n",
    "\n",
    "\n",
    "\n",
    "# here are some we don't need, but are fun\n",
    "# nltk.download('gutenberg')\n",
    "# nltk.download('brown')\n",
    "# nltk.download('reuters')\n",
    "# nltk.download('inaugural')\n",
    "# nltk.download('names')\n",
    "# nltk.download('state_union')\n",
    "\n",
    "\n",
    "# from nltk.corpus import gutenberg\n",
    "# from nltk.corpus import brown\n",
    "# from nltk.corpus import reuters\n",
    "# from nltk.corpus import inaugural\n",
    "# from nltk.corpus import names\n",
    "# from nltk.corpus import state_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: \n",
      "WORDNET\n",
      "2525 VBG verbs, gerund/present\n",
      "46405 nouns, of which:1101 NN nouns, singular\n",
      "1101 NNS nouns, plural\n",
      "22652 NNP nouns, proper, singular\n",
      "OTHER\n",
      "26 town prefixes\n",
      "17 town suffixes\n",
      "28 street names\n",
      "370099 random words\n",
      "936147 instances of \"we put the...in...\"13438 first names1000 surnames\n"
     ]
    }
   ],
   "source": [
    "# my own data, from various sources is in the 'corpora' folder\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# define variables\n",
    "# this stuff from my own data\n",
    "townprefixes = []\n",
    "townsuffixes = []\n",
    "street = []\n",
    "stupid = []\n",
    "weputthe = []\n",
    "firstnames = []\n",
    "surnames = []\n",
    "# this stuff to come from nltk\n",
    "nouns = []\n",
    "verbs = []\n",
    "adj = []\n",
    "nn = []  # NN\tnoun, singular 'desk'\n",
    "nns = [] # NNS\tnoun plural\t'desks'\n",
    "nnp = [] # NNP\tproper noun, singular\t'Harrison'\n",
    "vbg = [] # VBG\tverb, gerund/present participle\t'taking'\n",
    "\n",
    "\n",
    "with open('corpora/townprefixes.txt','r') as f:\n",
    "    townprefixes = [line.strip() for line in f]\n",
    "with open('corpora/townsuffixes.txt','r') as f:\n",
    "    townsuffixes = [line.strip() for line in f]\n",
    "with open('corpora/monopolystreets.txt','r') as f:\n",
    "    street = [line.strip() for line in f]\n",
    "with open('corpora/words_alpha.txt','r') as f:\n",
    "    stupid = [line.strip() for line in f]\n",
    "with open('corpora/we_put_the_x_in_y_old.txt','r') as f:\n",
    "    weputthe = [line.strip() for line in f]\n",
    "with open('corpora/top_5494_names_us_1990.txt','r') as f:\n",
    "    firstnames = [line.strip() for line in f]\n",
    "from nltk.corpus import names\n",
    "for i in range(len(names.words())):\n",
    "    firstnames.append(names.words()[i])\n",
    "with open('corpora/top_us_surnames.txt','r') as f:\n",
    "    surnames = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "for synset in list(wordnet.all_synsets('n')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    nouns.append(word)\n",
    "for synset in list(wordnet.all_synsets('v')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    verbs.append(word)\n",
    "for synset in list(wordnet.all_synsets('a')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    adj.append(word)\n",
    "\n",
    "sentence = ''\n",
    "for synset in list(wordnet.all_synsets('n')):\n",
    "    word = lemmatizer.lemmatize(synset.lemma_names()[0]).replace(\"_\",\" \")\n",
    "    sentence = sentence + word + ' '\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "length = len(tagged) - 1\n",
    "\n",
    "vbg = [item[0] for item in tagged if item[1]== 'VBG']\n",
    "nnp = [item[0] for item in tagged if item[1]== 'NNP']\n",
    "nns = [item[0] for item in tagged if item[1]== 'NNS']\n",
    "nn  = [item[0] for item in tagged if item[1]== 'NNS']\n",
    "\n",
    "# list all the fun stuff we now have\n",
    "print('loaded: \\n'\n",
    "      +'WORDNET\\n'\n",
    "      +str(len(vbg))+' VBG verbs, gerund/present\\n'\n",
    "      +str((len(nnp)+len(nnp)+len(nn)))+' nouns, of which:'\n",
    "      +str(len(nn))+' NN nouns, singular\\n'\n",
    "      +str(len(nns))+' NNS nouns, plural\\n'\n",
    "      +str(len(nnp))+' NNP nouns, proper, singular\\n'\n",
    "      +'OTHER\\n'\n",
    "      +str(len(townprefixes))+' town prefixes\\n'\n",
    "      +str(len(townsuffixes))+' town suffixes\\n'\n",
    "      +str(len(street))+' street names\\n'\n",
    "      +str(len(stupid))+' random words\\n'\n",
    "      +str(len(weputthe))+' instances of \\\"we put the...in...\\\"'\n",
    "      +str(len(firstnames))+' first names'\n",
    "      +str(len(surnames))+' surnames'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracery\n",
    "import tracery\n",
    "from tracery.modifiers import base_english\n",
    "\n",
    "# \"#something.capitalize# #category.s.capitalize#\",\n",
    "# \"#initials# #category.capitalize#\",\n",
    "# \"#initials# #superlative.capitalize# #category.capitalize.s#\",\n",
    "# \"#town# #category.capitalizeAll#\",\n",
    "# \"#firstname#\\'s #category.capitalizeAll#\",\n",
    "# \"#firstname#\\'s #superlative.capitalize# #category.capitalize#\",\n",
    "# \"#firstname#\\'s #category.capitalize.s#\",\n",
    "# \"#initials.capitalizeAll# #surname# (#category.capitalize#)\",\n",
    "# \"#initials.capitalizeAll# #surname.capitalize# #modifier.capitalize#\",\n",
    "# \"#initials.capitalizeAll# #surname.capitalize#\",\n",
    "# \"#initials.capitalizeAll# #noun.capitalize#\",\n",
    "# \"#noun.capitalize#\",\n",
    "# \"#adj.capitalize# #noun.capitalize#\",\n",
    "\n",
    "\n",
    "rules = {\n",
    "    # category\n",
    "    \"master\":\"[#setcategory#]#category##additional#\\n=================\\n\",\n",
    "    \"setcategory\":[\"[adj:#setadj#],[category:#cat#],[subcat:#additional#],[noun:#setnoun#],[additional:#setadditional#]\"],\n",
    "    \"cat\":[\"#noun.capitalize.s#\",\"#noun.capitalize.s#\",\"#adj.capitalize# #noun.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize#\",\"#adj.capitalize# #vbg.capitalize.s#\",\"#adj.capitalize# #vbg.capitalize#\"],\n",
    "    \"vbg\":vbg,\n",
    "    \"setnoun\":[\"#nnp.capitalize#\",\"#nns.capitalize#\",\"#modifier##nns#\"],\n",
    "    \"nnp\":nnp,\n",
    "    \"nns\":nns,\n",
    "    \"setadj\":adj,\n",
    "    \"setadditional\":[\"\",\"\",\"\",\" (#noun.capitalize#)\",\" (#noun.capitalize#, #noun.capitalize#)\",\" (#noun.capitalize#, #adj.capitalize# & #adj.capitalize#)\",\" (NOT #noun.capitalize#)\"],\n",
    "    \"modifier\":[\"\",\"\",\"\",\"\",\"\",\"Paleo\",\"Crypto\",\"Pseudo\",\"Trans\",\"Neuro\",\"Arch\",\"Pre-\",\"Post-\",\"X-\",\"Anarcho\",],\n",
    "\n",
    "    # companies\n",
    "    \"listing\":[\"[#companyinfo#]\\*\\*#name.capitalize#\\*\\*\\ \\ \\n\\_#motto#\\_\\ \\ \\n#address#\\ \\ \\n☎ #phone#\\n\\n\"],\n",
    "\n",
    "    # set company info\n",
    "    \"companyinfo\":[\"[town:#settown#],[name:#setname#],[address:#setaddress#],[phone:#setphone#],[motto:#setmotto#]\"],\n",
    "\n",
    "    # town\n",
    "    \"settown\":\"#prefix.capitalize##suffix#\",\n",
    "    \"prefix\": townprefixes,\n",
    "    \"suffix\": townsuffixes,\n",
    "\n",
    "    # company name\n",
    "      \"setname\":[\n",
    "        \"#something.capitalize# #category.s.capitalize#\",\n",
    "        \"#initials# #category.capitalize#\",\n",
    "        \"#initials# #superlative.capitalize# #category.capitalize.s#\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize# #and.capitalize#\",\n",
    "        \"#noun.capitalize# #and.capitalize#\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize#\",\n",
    "        \"#initials.capitalizeAll# #surname# (#category.capitalize#)\",\n",
    "        \"#initials.capitalizeAll# #noun.capitalize# #and.capitalize#\",\n",
    "        \"#category.capitalize# (#initials.capitalizeAll# #surname.capitalize# #and#)\",\n",
    "        \"#firstname.capitalize#\\'s #category.capitalize#\",\n",
    "        \"#firstname.capitalize#\\'s #noun.capitalize#\",\n",
    "        \"#town.capitalize# #adj.capitalize#\",\n",
    "        \"#town.capitalize# #noun.capitalize#\",\n",
    "        \"#town.capitalize# #category.capitalize#\",\n",
    "        \"#town.capitalize# #adj.capitalize# #and#\",\n",
    "        \"#town.capitalize# #noun.capitalize# #and\",\n",
    "        \"#town.capitalize# #category.capitalize# #and#\",\n",
    "        \"#initials.capitalizeAll##initials.capitalizeAll##initials.capitalizeAll# #and#\",\n",
    "        \"#initials.capitalizeAll# #and# (#town.capitalize#)\",\n",
    "        \"#noun.capitalize# #and.capitalize#\",\n",
    "        \"#firstname#\\'s #superlative.capitalize# #category.capitalize#\",\n",
    "        \"#setadj.capitalize# #noun.capitalize# #initials.capitalizeAll#\"\n",
    "      ],\n",
    "    \"initials\":[\"#l.capitalize#.\",\"#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.#l.capitalize#.\",\"#l.capitalize#.#l.capitalize#.\",\"#l.capitalize##l.capitalize#\",\"#firstname.capitalize# #l.capitalize#.\"],\n",
    "    \"l\":[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"],\n",
    "    \"firstname\":firstnames,\n",
    "    \"surname\":surnames,\n",
    "    \"and\":[\"& Sons\",\"& Co\",\"and Company\",\"Incorporated\",\"& #nnp.capitalize#\",\"Holdings\"],\n",
    "\n",
    "\n",
    "    # address\n",
    "    \"setaddress\": \"#streetname.capitalize#, #town.capitalize#\",\n",
    "    \"number\": [\"#d0#\",\"#d0##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\",\"#d0##d##d##d#\"],\n",
    "    \"streetname\":[\"#number# #street# #streettype#\",\"#number# #street# #streettype#\",\"#street# & #street#\"],\n",
    "    \"streettype\":[\"Avenue\",\"Street\",\"Road\",\"Lane\",\"Parkway\",\"St\",\"Ave\"],\n",
    "    \"street\": street,\n",
    "    \"town\": \"#prefix.capitalize##suffix#\",\n",
    "    \"zipcode\": \"#d##d##d##d##d#\",\n",
    "    \"d\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],\n",
    "    \"d0\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"],\n",
    "    \"d1\":[\"0\",\"1\"],\n",
    "    \"d19\":[\"18\",\"19\",\"19\"],\n",
    "    \"d20\":[\"20\"],\n",
    "\n",
    "    # phone number\n",
    "    \"setphone\":[\"#d0##d##d#-#d##d##d##d#\"],\n",
    "\n",
    "\n",
    "    # motto\n",
    "    \"setmotto\": [\"#motto#\",\"#tellem#\",\"#weputthexiny#\",\"#weputthexiny#\",\"The #superlative# #thing# #located# #town#\",\"#owned.capitalize#\",\"#stuff#\",\"#directions#\",\"#youlike##punctuation#\",\"#youlike# \\n#directions#\",\"#localpromo#\"],\n",
    "    \"owned\":[\"#division.a# of #something.capitalize# #inc#\",\"#division.a# of #something.capitalize# #inc.capitalize#\",\"Part of the #something.capitalize# #inc#\"],\n",
    "    \"owned2\":[\"#division.a# of #acronym.capitalize# #inc#\",\"#division.a# of #acronym.capitalize# #inc.uppercase#\",\"Part of the #acronym.capitalize# #inc#\"],\n",
    "    \"acronym\": [\"#letter.uppercase#.#letter.uppercase#.\",\"#letter.uppercase#.#letter.uppercase#.#letter.uppercase#.\",\"#letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase##letter.uppercase#\",\"#letter.uppercase#-#letter.uppercase#-#letter.uppercase#-#letter.uppercase#\"],\n",
    "    \"inc\": [\"Family\",\"Network\",\"Network of Companies\",\"LLC\",\"PLC\",\"L.L.C.\"],\n",
    "    \"something\": [\"#nnp#\",\"#nns#\"],\n",
    "    \"division\":[\"Proud Member\",\"Founding Member\"],\n",
    "    \"superlative\": [\"biggest\",\"best\",\"oldest\",\"rarest\",\"most sought-after\",\"nicest\",\"prettiest\"],\n",
    "    \"thing\": [\"prices\",\"selection\",\"collection\",\"range\",\"budget option\",\"#size# selection\"],\n",
    "    \"size\": [\"mid-range\",\"large-scale\",\"huge\",\"budget\",\"high budget\",\"upscale\"],\n",
    "    \"located\": [\"in\",\"near\",\"#dir# of\"],\n",
    "    \"dir\": [\"north\",\"south\",\"east\",\"west\",\"just outside\"],\n",
    "    \"stuff\": [\"#something.capitalize#, #something.capitalize#, & #something.capitalize#!\",\"#something.capitalize# • #something.capitalize# • #something.capitalize#\",\"#wevegot# #something.capitalize#!\"],\n",
    "    \"wevegot\": [\"We've got\",\"You'll love our\",\"Why not try\",\"Take a look at our\",\"Relax with\",\"Prod our\"],\n",
    "    \"directions\":[\"#action# #dir# at #town#\",\"#action# #dir# at #place#, #action# for #distance# #measurement#\",\"#place.capitalize#: #action# #dir# at #town#, #action# #dir# at #town#, #action# #dir# at #town#\"],\n",
    "    \"place\":[\"#town#\",\"Junction #d0##d#\",\"Interstate #d0##d#\",\"the #something.capitalize#\"],\n",
    "    \"action\":[\"Turn\",\"Continue Straight\",\"Continue\",\"Drive\"],\n",
    "    \"distance\": [\"#d0#\",\"#d0##d#\"],\n",
    "    \"measurement\":[\"miles\",\"feet\"],\n",
    "    \"youlike\":[\n",
    "        \"#something.capitalize# #timespan#!\",\n",
    "        \"You like #stuff.capitalize#? We've got it!\",\n",
    "        \"Have you ever wanted #something.capitalize#?\",\n",
    "        \"Have you ever wanted #something.capitalize#? We have #something.capitalize#!\",\n",
    "        \"Dreaming of #something.capitalize#?!\",\n",
    "        \"Why not try #something.capitalize# #timespan#?\",\n",
    "        \"You want #category.capitalize#? We've got #category.capitalize#!\",\n",
    "        \"#category.capitalize#: Just the way you like it\",\n",
    "        \"You've never seen #category.capitalize# this #size#\",\n",
    "        \"Our secret is in our #nnp.capitalize#\",\n",
    "        \"Family owned #nns.capitalize#\",\n",
    "    ],\n",
    "    \"timespan\":[\"now\",\"tomorrow\",\"today\",\"right now\",\"immediately\",\"the next chance you get\"],\n",
    "    \"weputthe\":[\"We put the #something# in #something.s#\"],\n",
    "    \"tell\":[\"Tell them\",\"Tell 'em\",\"Just say\"],\n",
    "    \"amazingjob\":[\"#qualifier# #job#\"],\n",
    "    \"qualifier\":[\"top\",\"local celebrity\",\"well-known\",\"your favourite\",\"imaginary friend\",\"family favourite\",\"the one and only\",\"phenomenal\",\"the best\",\"excellent\",\"mediocre\",\"mid-range\",\"smooth moving\"],\n",
    "    \"job\":[\"chef\",\"TV host\",\"Psychic\",\"carpenter\",\"dentist\",\"orthodontist\",\"paleontologist\",\"captain\",\"musician\"],\n",
    "    \"tellem\":[\"#tell# #firstname# sent you!\",\"Recommended by #amazingjob# #firstname.capitalize# #surname.capitalize#\"],\n",
    "    \"tell\":[\"Tell them\",\"Tell 'em\",\"Just say\"],\n",
    "    \"est\":[\"Established #year#\",\"Since #year#\",\"Serving #town# since #year#\",\"Helping you with #category# since #year#\",\"In #town.capitalize# since #year#\"],\n",
    "    \"year\":[\"#d19##d##d#\",\"#d19##d##d#\",\"#d20##d1##d#\"],\n",
    "    \"punctuation\":[\"!\",\".\",\"!!\",\"!\",\"!!!\",\"?!\"],\n",
    "\n",
    "\n",
    "    \"weputthexiny\":[\"#weputthe#!\",\"#weputthe#!!!\",\"#weputthe#\"],\n",
    "    \"weputthe\":weputthe,\n",
    "    \"localpromo\":[\"Hear our advert on #localstation#\",\"You might have heard about us on #localstation#\",\"Proud sponsors of #localstation#\"],\n",
    "    \"localstation\":[\"#something.capitalize# #d0##d#.#d0# FM\",\"#qualifier# local station #something.capitalize# #d0##d#.#d0# FM\",\"1#d##d#.#d0# FM\",\"the Internet\",\"the radio\"],\n",
    "    \n",
    "    # markdown stuff\n",
    "    \"markdownheader\":\"\\-\\-\\-\\nlayout: page \\ntitle: #category#\\n\\n\\-\\-\\-\\n\\n\\n\\# #category#\\n\\n\\n \",\n",
    "    \"pagetitle\":\"#category#.md\",\n",
    "    \"markdownlisting\":[\"[#companyinfo#]\\#\\# #name.capitalize# \\n\\n\\#\\# #motto#\\n\\n#address#\\ \\ \\n☎ #phone#\\n\\n\"],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grammar = tracery.Grammar(rules) # create a grammar object from the rules\n",
    "grammar.add_modifiers(base_english) # add pre-programmed modifiers\n",
    "\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to markdown\n",
    "\n",
    "for i in range(5000):\n",
    "    print (grammar.flatten(\"#master#\")) # and flatten, starting with origin rule\n",
    "    with open('output/pages/'+grammar.flatten(\"#pagetitle#\"),'w') as f:\n",
    "        f.write(grammar.flatten(\"#markdownheader#\"))\n",
    "        for j in range(random.randrange(1,100)):\n",
    "            f.write(grammar.flatten(\"#listing#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
